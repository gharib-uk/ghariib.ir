<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>The forecast is clear: clouds on e-paper, powered by the cloud</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>The forecast is clear: clouds on e-paper, powered by the cloud</h1>
			<b><time>02.01.2025 00:00</time></b>
		       

			<div>
				<p>I’ve noticed that many shops are increasingly using e-paper displays. They’re impressive: high contrast, no backlight, and no visible cables. Unlike most electronics, these displays are seamlessly integrated and feel very natural. This got me wondering: is it possible to use such a display for a pet project? I want to experiment with this technology myself.</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2Be8SEo0lqoZ0t10tPbtcT/ffa6f9263df05392d7c4408e9c98bc28/Screenshot_2024-12-23_at_15.26.23.png" alt="" />
</figure>


</p>
<p>(source)</p>
<p>My main goal in this project is to understand the hardware and its capabilities. Here, I&rsquo;ll be using an e-paper display to show the current weather, but at its core, I’m simply feeding data from a website to the display. While it sounds straightforward, it actually requires three layers of software to pull off. Still, it’s a fun challenge and a great opportunity to work with both embedded hardware and Cloudflare Workers.</p>
<h2 id="sourcing-the-hardware">Sourcing the hardware</h2>
<p>For this project, I&rsquo;m using components from Waveshare. They offer a variety of e-paper displays, ranging from credit card-sized to A4-sized models. I chose the 7.5-inch, two-color &ldquo;e-Paper (G)&rdquo; display. For the controller, I&rsquo;m using a Waveshare ESP32-based universal board. With just these two components — a display and a controller — I was ready to get started.</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7A6SqnMUHriAgRAAJM5Mbj/0d1282a915a1192d276e7dff1b901013/Screenshot_2024-12-23_at_15.25.45.png" alt="" />
</figure>


</p>
<p>When the components arrived, I carefully connected the display’s ribbon cable to the ESP32 board. Even though this step isn’t documented anywhere, it was simple and almost impossible to get wrong. Best of all, no soldering was needed!</p>
<p>That’s pretty much it for the hardware setup! I’m keeping the device powered with a 5V supply through a micro-USB connection.</p>
<h2 id="one-layer-of-hardware">One layer of hardware </h2>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6WNVmUFDsLdewKrZJr4Otl/ae5eb976d1c7dc176cc288619b18c036/image1.png" alt="" />
</figure>


</p>
<p>(source)</p>
<p>This was my first time working with the ESP32 CPU family, and I’m really impressed. It’s a system-on-chip controller with built-in Bluetooth and Wi-Fi. It’s relatively fast, very power-efficient, and quite popular in DSP (digital signal processing) applications. For example, your audio device might be powered by a CPU like this. Interestingly, the newer models have switched to the RISC-V instruction set.</p>
<p>For our purposes, we’ll only scratch the surface of what the ESP32 is capable of. The chip is straightforward to work with, thanks to the familiar Arduino environment. A great starting point is the demo provided by Waveshare. It sets up a web page where you can easily upload a custom image to the display.</p>
<p>To run the demo you need to:</p>
<ul>
<li>
<p>Install the Arduino IDE.</p>
</li>
<li>
<p>Fix permissions of the <code>/dev/ACM0</code> device.</p>
</li>
<li>
<p>Install &ldquo;Additional Boards Manager URL&rdquo; as per the instructions, and install the &ldquo;esp32 by expressif&rdquo; bundle.</p>
</li>
<li>
<p>Open the &ldquo;Loader_esp32wf&rdquo; example downloaded from waveshare.</p>
</li>
<li>
<p>Change the Wi-Fi name, password and IP address in the Arduino IDE <code>srvr.h</code> tab.</p>
</li>
</ul>
<p>Once everything is set up, you should be able to connect to the ESP32’s IP address and use the simple web interface to upload an image to the display.</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5KUXIJqF1J9hQqHISumuaV/85c211b315f338ba2339b4a7120162d4/Screenshot_2024-12-23_at_15.24.46.png" alt="" />
</figure>


</p>
<p>With a simple click of the &ldquo;Upload Image&rdquo; button, the magic happens: the e-paper display comes to life, showcasing the uploaded image.</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3qxQCybmGmpxufDfU69OcY/d995257657f5991dd1d152b59ae2b84e/Screenshot_2024-12-23_at_15.24.09.png" alt="" />
</figure>


</p>
<p>With the demo up and running, we can move on to the next step: figuring out how to render a web page on the e-paper display.</p>
<h2 id="three-layers-of-software">Three layers of software</h2>
<p>The ESP32 comes with some limitations. It has 520 KiB of RAM, 4 MiB of flash, and a 240 MHz clock speed. While this is fine for tasks like connecting to Wi-Fi or fetching a simple URL, it’s not powerful enough for more demanding tasks, such as parsing JSON or rendering an entire web page.</p>
<p>There are basic Arduino libraries for handling bitmaps, which can draw rectangles and render simple fonts, but manually managing layout doesn&rsquo;t sound appealing to me. A better approach is to play to the ESP32’s strengths — fetching and displaying bitmaps — and delegate the more complex task of HTML rendering to a more powerful server. </p>
<p>Let’s break the problem into three layers:</p>
<ol>
<li>
<p><strong>ESP32 (Display Layer):</strong> The ESP32 will periodically, say every minute, fetch a pre-rendered bitmap from the server and display it on the e-paper screen. This keeps the ESP32&rsquo;s tasks lightweight and manageable.</p>
</li>
<li>
<p><strong>Server A (Rendering Layer):</strong> This server will fetch the desired website, render it, and rasterize it into a bitmap format. Its job is to prepare a bitmap that the ESP32 can handle without additional processing.</p>
</li>
<li>
<p><strong>Server B (Content Layer):</strong> This server hosts the actual website with the HTML and CSS content. In this case, it will provide the local weather data in a styled format, ready to be fetched and rendered by Server A.</p>
</li>
</ol>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3V3LbBwfxhaWMukCVw0Tx/ab272f72ee2e45879acf3fea9a0fe75e/image8.png" alt="" />
</figure>


</p>
<h3 id="esp32-display-layer">ESP32 (Display Layer)</h3>
<p>The ESP32 provides some great higher-level libraries to simplify development. For this project, we’ll need three key components:</p>
<ol>
<li>
<p><strong>Wi-Fi Arduino Library</strong>**:** To connect the ESP32 to a Wi-Fi network.</p>
</li>
<li>
<p><strong>HTTP Arduino Library</strong>**:** To handle HTTP requests and fetch the rendered bitmap from the server.</p>
</li>
<li>
<p><strong>EPD (e-Paper Display) Driver:</strong> To control the e-paper display and render the fetched bitmap.</p>
</li>
</ol>
<p>These libraries make it much easier to implement the required functionality without dealing with low-level details.</p>
<p>Here&rsquo;s my ESP32 Arduino project code. It&rsquo;s actually pretty straightforward:</p>
<ul>
<li>
<p>First, it connects to Wi-Fi</p>
</li>
<li>
<p>Then, it fetches a rendered bitmap from an HTTP endpoint</p>
</li>
<li>
<p>Then it pushes it to the e-paper display if needed</p>
</li>
<li>
<p>Waits a minute</p>
</li>
<li>
<p>And repeats the whole process forever</p>
</li>
</ul>
<p>E-paper displays typically start to degrade after about one million refresh cycles. To preserve the display&rsquo;s lifespan, I’m being extra careful to avoid unnecessary refreshes.</p>
<h3 id="server-a-rendering-layer">Server A (Rendering Layer)</h3>
<p>Now for the exciting part! We need an online service that can fetch a website, render it, rasterize it to fit our small monochromatic display, and return it as a display-sized binary blob. Initially, I considered using headless Chrome paired with an ImageMagick script, but then I discovered Cloudflare’s <strong>Browser Rendering API</strong>, which fits our needs perfectly.</p>
<p>This API can be used quite trivially and nicely fits our needs. Here&rsquo;s the typescript worker code, and there are two particularly interesting parts: handling a remote browser and dithering.</p>
<h3 id="remote-browser-api">Remote Browser API</h3>
<p>First, see how easy it is to render a website as a PNG using Browser Rendering:</p>
<pre tabindex="0"><code>if (!browser) {
browser = await puppeteer.launch(env.MYBROWSER, { keep_alive: 600000 });
launched = true;
}
sessionId = browser.sessionId();

const page = await browser.newPage();
await page.setViewport({
width: 480,
height: 800,
deviceScaleFactor: 1,
})

await page.goto(url);
img = (await page.screenshot()) as Buffer;
</code></pre><p>I’m genuinely surprised at how practical and effective this approach is. While the remote browser startup isn’t exactly fast — it can take a few seconds to generate the screenshot — it’s not an issue for my use case. The delay is perfectly acceptable, especially considering how much work is offloaded to the cloud.</p>
<h4 id="dithering">Dithering</h4>
<p>To prepare the bitmap for the ESP32, we need to decode the PNG, reduce the color palette to monochromatic, and apply dithering. Here&rsquo;s the dithering code:</p>
<pre tabindex="0"><code>function ditherTwoBits(px: Buffer,
                       width: number,
                       height: number
                      ): Buffer {
    px = new Float32Array(px);

    for (let y = 0; y &lt; height; y++) {
        for (let x = 0; x &lt; width; x++) {
            const old_pixel = px[y * width + x];
            const new_pixel = old_pixel &gt; 128 ? 0xff : 0x00;

            const quant_error = (old_pixel - new_pixel) / 16.0;
            px[(y + 0) * width + (x + 0)] = new_pixel;
            px[(y + 0) * width + (x + 1)] += quant_error * 7.;
            px[(y + 1) * width + (x - 1)] += quant_error * 3.;
            px[(y + 1) * width + (x + 0)] += quant_error * 5.;
            px[(y + 1) * width + (x + 1)] += quant_error * 1.;
        }
    }

    return Buffer.from(Uint8ClampedArray.from(px));
}
</code></pre><p>This was my first time experimenting with dithering, and it’s been a lot of fun! I was surprised by how straightforward the process is and that it’s fully deterministic. Now that I understand the details of the algorithm, I can’t help but notice its subtle side effects everywhere — in printed materials, on screens, and even in design choices around me. It’s fascinating how something so simple has such a broad impact!</p>
<p>To deploy this code as a Cloudflare Worker, you only need to install the required dependencies, configure the <code>wrangler.toml</code> file, and publish the code. Here’s a step-by-step guide:</p>
<pre tabindex="0"><code>sudo apt install npm
cd worker-render-raster
npm install wrangler
npm install @cloudflare/puppeteer --save-dev
npm install fast-png --save-dev
npx wrangler kv:namespace create KV
npx wrangler kv:namespace create KV --preview
</code></pre><p>With this out of the way, you can run the code:</p>
<pre tabindex="0"><code>2025-01-e-paper/worker-render-raster$ npx wrangler dev --remote

 ⛅️ wrangler 3.99.0
-------------------

Your worker has access to the following bindings:
- KV Namespaces:
  - KV: XXX
- Browser:
  - Name: BROWSER
[wrangler:inf] Ready on http://localhost:46131
⎔ Starting remote preview...
Total Upload: 755.39 KiB / gzip: 149.05 KiB
╭─────────────────────────────────────────────────────────────────────────────────────────────────╮
│  [b] open a browser, [d] open devtools, [l] turn on local mode, [c] clear console, [x] to exit  │
╰─────────────────────────────────────────────────────────────────────────────────────────────────╯
</code></pre><p>With everything set up, you can now open a browser and see a rendered and rasterized version of a website, processed through your Cloudflare Worker! For example, here’s how the <strong>1.1.1.1</strong> page looks in a 800x480 monochromatic resolution, complete with dithering:</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6awlaJqO4LduSLwvUXQbYJ/b2b43d14c0a8d44fbed1ed4bc2a4de12/Screenshot_2024-12-23_at_15.23.14.png" alt="" />
</figure>


</p>
<p>This demonstrates how effectively the Worker can handle rendering, rasterizing, and adapting web content for an e-paper display. It’s quite satisfying to see the pipeline in action.</p>
<h3 id="server-b-content-layer">Server B (Content Layer)</h3>
<p>To create the weather panel, I designed a simple HTML and CSS page and published it as another Cloudflare Worker. This time, I used Python in Cloudflare Workers because it felt more straightforward, especially since the site needs to query an external weather API. The simplicity of the code was surprising and made the process smooth.</p>
<pre tabindex="0"><code>async def on_fetch(request, env):
    cached = await env.KV.get(&#34;weather&#34;)
    if cached:
        cached = json.loads(cached)
    else:
        u = &#34;https://api.open-meteo.com/...&#34;
        a = await fetch(u)
        result = await a.text()
        cached = json.loads(result)
        await env.KV.put(&#34;weather&#34;, json.dumps(cached))
    return Response.new(render(...), headers=[(&#39;content-type&#39;, &#39;text/html&#39;)])
</code></pre><p>Here’s how it appears in a normal browser compared to the rendered and rasterized version by our worker:</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5irsWxy9nIgTRirXP6l8Nh/a4bb0d31df18c8385ddd96c4542941d0/Screenshot_2024-12-23_at_15.19.21.png" alt="" />
</figure>


</p>
<h2 id="summary">Summary</h2>
<p>Finally, the display deserves a proper frame. Here’s the finished version:</p>
<p>
<figure>
  <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1Dymme1r2SJ8rAKRJjyl0K/4fa344362ca037607c7989dbf47b7fff/image11.png" alt="" />
</figure>


</p>
<p>I started this project wanting to experiment with an e-paper display hardware, but I ended up spending most of my time writing software—and it turned out to be surprisingly enjoyable across all layers:</p>
<ul>
<li>
<p><strong>ESP32:</strong> The CPU is fantastic. Programming it is straightforward, thanks to powerful built-in libraries that simplify development.</p>
</li>
<li>
<p><strong>Cloudflare Worker Browser Rendering:</strong> This is an underrated but incredibly powerful technology. It made implementing features like the Floyd–Steinberg dithering algorithm surprisingly easy.</p>
</li>
<li>
<p><strong>Cloudflare Worker Python:</strong> Although still in beta, it worked flawlessly for my needs and was a great fit for handling API requests and serving dynamic content.</p>
</li>
</ul>
<p>It’s remarkable how much you can achieve with relatively inexpensive hardware and free Cloudflare services.</p>
<p>Go to Source</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/a-visual-summary-of-sans-new2cyber-summit-2025/">A Visual Summary of SANS New2Cyber Summit 2025</a></li>
				
				<li><a href="/posts/advance-your-cybersecurity-career-how-to-use-tuition-reimbursement-for-sec406/">Advance Your Cybersecurity Career: How to Use Tuition Reimbursement for SEC406</a></li>
				
				<li><a href="/posts/continuous-penetration-testing-a-consultants-perspective/">Continuous Penetration Testing - A Consultant’s Perspective</a></li>
				
				<li><a href="/posts/desktop-4-39-smarter-ai-agent-docker-desktop-cli-in-ga-and-effortless-multi-platform-builds/">Desktop 4.39: Smarter AI Agent, Docker Desktop CLI in GA, and Effortless Multi-Platform Builds</a></li>
				
				<li><a href="/posts/docker-engine-v28-hardening-container-networking-by-default/">Docker Engine v28: Hardening Container Networking by Default</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
