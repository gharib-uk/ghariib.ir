<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>Using Kafka as a Fast Correlation Engine</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>Using Kafka as a Fast Correlation Engine</h1>
			<b><time>04.01.2025 00:00</time></b>
		       
		           <a href="/tags/ai">ai</a>
        	       
		           <a href="/tags/cybersecurity">cybersecurity</a>
        	       
		           <a href="/tags/security">security</a>
        	       
		           <a href="/tags/soc">soc</a>
        	       
		           <a href="/tags/software">software</a>
        	       

			<div>
				<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-Streams-400x234.jpg" alt="" />
</figure>


</p>
<p>In this article, we explore how Kafka Streams can be utilized for filtering and correlating events in real time, effectively transforming Kafka into a high-speed correlation engine. By leveraging the capabilities of <strong>ksqlDB</strong>, you can deploy content rules and filter alerts directly within Kafka. This approach enables real-time filtration and aggregation of log event flows using an intuitive SQL-like language.</p>
<h2 id="environment-setup">Environment Setup</h2>
<p>Our environment includes the following components:</p>
<ul>
<li><strong>Test Kafka Cluster</strong>: A single-node Kafka cluster operating in KRaft mode (Kafka Raft Metadata mode). KRaft replaces the traditional ZooKeeper setup, simplifying Kafka’s architecture and improving operational efficiency.</li>
<li><strong>Kafka-UI</strong>: A graphical user interface for managing and monitoring Kafka clusters. It allows easy visualization and manipulation of topics, schemas, and consumer groups.</li>
<li><strong>ksqlDB Server</strong>: This component enables real-time stream processing with SQL-like queries. It connects to the Kafka cluster, enabling filtering, transformation, and aggregation of streaming data.</li>
<li><strong>ksqlDB CLI</strong>: A command-line interface for interacting with the ksqlDB server. It allows users to write and execute SQL-like queries, define streams, and interact with data programmatically.</li>
</ul>
<p>Our TEST environment:
<figure>
  <img src="https://socprime.com/wp-content/uploads/kafka-test-environment.png" alt="" />
</figure>


</p>
<h2 id="test-environment-overview">Test Environment Overview</h2>
<p><strong>Data Source</strong></p>
<p>We use a <strong>“wineventlogs”</strong> topic in Kafka, populated by the <strong>Elastic Winlogbeat agent</strong>, which forwards Windows Event Logs in JSON format.</p>
<p><strong>Objective</strong></p>
<p>Filter events based on <strong>SOC Prime TDM content</strong> and save the results to a <strong>“windows_alerts”</strong> topic for further consumption.</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/kafka-topics.png" alt="" />
</figure>


</p>
<p>For example we would like to filter events based on the SOC Prime TDM content and save message to result “windows_alerts” topic for further consuming:</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/kafka-windows-alerts.png" alt="" />
</figure>


</p>
<h2 id="step-by-step-implementation">Step-by-Step Implementation</h2>
<p><strong>1. Connect to the ksqlDB CLI</strong><br>
Use the following command to connect to the ksqlDB CLI:</p>
<pre tabindex="0"><code>podman exec -it ksqldb-cli ksql http://ksqldb-server:8088
</code></pre><p><strong>2. List Current Topics</strong><br>
To view all topics in your Kafka cluster, use:
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-Cluster.png" alt="" />
</figure>


</p>
<p><strong>3. Examine the Topic Schema</strong><br>
Inspect the <strong>wineventlogs</strong> topic to understand its data structure:</p>
<pre tabindex="0"><code>PRINT wineventlogs;
</code></pre><p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-logs.png" alt="" />
</figure>


</p>
<p>You can also use Kafka-UI to view the messages stored in the topic.</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-UI.png" alt="" />
</figure>


</p>
<h2 id="defining-a-stream-schema">Defining a Stream Schema</h2>
<p>To process data in ksqlDB, you must first define a stream schema that matches the JSON structure of your data. Below is the <strong>CREATE STREAM</strong> statement for the wineventlogs topic:</p>
<pre tabindex="0"><code>CREATE STREAM WINLOGEVENTS (
	`@timestamp` VARCHAR,
	`@metadata` STRUCT&lt;
    	beat VARCHAR,
    	type VARCHAR,
    	version VARCHAR
	&gt;,
	winlog STRUCT&lt;
    	version INT,
    	event_data STRUCT&lt;
        	ProcessId VARCHAR,
        	CommandLine VARCHAR,
        	SubjectDomainName VARCHAR,
        	MandatoryLabel VARCHAR,
        	SubjectUserName VARCHAR,
        	SubjectLogonId VARCHAR,
        	TargetUserSid VARCHAR,
        	SubjectUserSid VARCHAR,
        	TargetUserName VARCHAR,
        	ParentProcessName VARCHAR,
        	TargetLogonId VARCHAR,
        	NewProcessName VARCHAR,
        	TargetDomainName VARCHAR,
        	TokenElevationType VARCHAR,
        	NewProcessId VARCHAR
    	&gt;,
    	api VARCHAR,
    	task VARCHAR,
    	process STRUCT&lt;
        	pid INT,
        	thread STRUCT&lt;
            	id INT
        	&gt;
    	&gt;,
    	keywords ARRAY&lt;VARCHAR&gt;,
    	provider_guid VARCHAR,
    	opcode VARCHAR,
    	record_id BIGINT,
    	computer_name VARCHAR,
    	event_id VARCHAR,
    	provider_name VARCHAR,
    	channel VARCHAR
	&gt;,
	event STRUCT&lt;
    	created VARCHAR,
    	code VARCHAR,
    	kind VARCHAR,
    	provider VARCHAR,
    	outcome VARCHAR,
    	action VARCHAR
	&gt;,
	log STRUCT&lt;
    	level VARCHAR
	&gt;,
	message VARCHAR,
	host STRUCT&lt;
    	name VARCHAR,
    	hostname VARCHAR,
    	architecture VARCHAR,
    	os STRUCT&lt;
        	version VARCHAR,
        	family VARCHAR,
        	name VARCHAR,
        	kernel VARCHAR,
        	build VARCHAR,
        	type VARCHAR,
        	platform VARCHAR
    	&gt;,
    	id VARCHAR,
    	ip ARRAY&lt;VARCHAR&gt;,
    	mac ARRAY&lt;VARCHAR&gt;
	&gt;,
	ecs STRUCT&lt;
    	version VARCHAR
	&gt;,
	agent STRUCT&lt;
    	name VARCHAR,
    	type VARCHAR,
    	version VARCHAR,
    	ephemeral_id VARCHAR,
    	id VARCHAR
	&gt;
) WITH (
	KAFKA_TOPIC = &#39;wineventlogs&#39;,
	VALUE_FORMAT = &#39;JSON&#39;
);
</code></pre><p>So, stream successfully created:</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-stream.png" alt="" />
</figure>


</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka-stream-2.png" alt="" />
</figure>


</p>
<p>Lets test our WINLOGEVENTS stream, filter the stream as new data arrives:</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Kafka_winlogevents.png" alt="" />
</figure>


</p>
<p>So we see, that our stream works properly and we see all throughput messages.</p>
<h2 id="creating-a-filtered-stream">Creating a Filtered Stream</h2>
<p><strong>Create a New Kafka Topic</strong><br>
First, create a topic for filtered messages windows_alerts:</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/New-Kafka-Topic.png" alt="" />
</figure>


</p>
<p><strong>Define a New Stream for Alerts</strong><br>
Filter events using the SOC Prime TDM rule <strong>Possible Antivirus or Firewall Software Enumeration (via process_creation)</strong>. Below is the <strong>CREATE STREAM</strong> statement:</p>
<ul>
<li>CommandLine  according to data will be mapped to winlog-&gt;event_data-&gt;CommandLine</li>
<li>ParentImage according to data will be mapped to  winlog-&gt;event_data-&gt;ParentProcessName</li>
<li>Host to host-&gt;hostname</li>
</ul>
<pre tabindex="0"><code>CREATE STREAM WINDOWS_ALERTS WITH (KAFKA_TOPIC = &#39;windows_alerts&#39;) AS SELECT host-&gt;hostname AS Host, winlog-&gt;event_data-&gt;CommandLine AS CommandLine, winlog-&gt;event_data-&gt;ParentProcessName AS ParentImage FROM WINLOGEVENTS WHERE ( (winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%AntiSpywareProduct%&#39; OR winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%AntiVirusProduct%&#39; OR winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%FirewallProduct%&#39;) AND NOT (winlog-&gt;event_data-&gt;ParentProcessName LIKE &#39;%phpstorm64.exe&#39; OR winlog-&gt;event_data-&gt;ParentProcessName LIKE &#39;%pycharm64.exe&#39;) AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%displayName%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%productState%&#39;) OR ( winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%Win32_Process%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%AvastUI.exe%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%AvastSvc.exe%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%FortiWF.exe%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%xagt.exe%&#39; AND winlog-&gt;event_data-&gt;CommandLine LIKE &#39;%fcappdb.exe%&#39; );
</code></pre><p>So we defined the stream with filtering by our rule, lets test it!</p>
<h2 id="testing-the-filtered-stream">Testing the Filtered Stream</h2>
<p><strong>P****roduce a Test Message</strong><br>
Publish a test message containing “fcappdb.exe” in the CommandLine field to the wineventlogs topic.</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Test-message_Kafka.png" alt="" />
</figure>


</p>
<p><strong>Check the Filtered Stream</strong><br>
Inspect the WINDOWS_ALERTS stream:<br>
SELECT * FROM WINDOWS_ALERTS EMIT CHANGES;</p>
<p>
<figure>
  <img src="https://socprime.com/wp-content/uploads/Check-filtered-stream_Kafka_1.png" alt="" />
</figure>


</p>
<p>And we see than Alert is here, cool!</p>
<p>And check the topic- we see the result correlated message here:
<figure>
  <img src="https://socprime.com/wp-content/uploads/Check-filtered-stream_Kafka_2.png" alt="" />
</figure>


</p>
<p>Thats it!</p>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>Using Kafka Streams with ksqlDB, you can build a high-performance correlation engine (like in SIEM). This approach allows for real-time event filtering, reducing reliance on traditional SIEM solutions. Additionally, by integrating content from <strong>SOC Prime TDM</strong>, you can enrich your correlation logic to detect sophisticated threats efficiently.</p>
<p>The post Using Kafka as a Fast Correlation Engine appeared first on SOC Prime.</p>
<p>Go to Source</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/2025-03-21-cve-2025-30345---openslides-cross-site-/">CVE-2025-30345 - OpenSlides Cross-Site Scripting XSS</a></li>
				
				<li><a href="/posts/2025-03-21-cve-2025-30342---openslides-cross-site-/">CVE-2025-30342 - OpenSlides Cross-Site Scripting XSS</a></li>
				
				<li><a href="/posts/2025-03-21-cve-2025-30343---openslides-directory-t/">CVE-2025-30343 - OpenSlides Directory Traversal Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-21-cve-2025-30344---openslides-timing-base/">CVE-2025-30344 - OpenSlides Timing-Based Authentication Bypass</a></li>
				
				<li><a href="/posts/2025-03-21-cve-2024-50053---zohocorp-manageengine-/">CVE-2024-50053 - Zohocorp ManageEngine ServiceDesk Plus Stored Cross-Site Scripting</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
